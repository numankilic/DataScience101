{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Numan\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "survey_19= pd.read_csv(\"survey_results_public.csv\")\n",
    "\n",
    "\n",
    "#okunabilirlik açısından kolay olsun diye 1.projedeki gibi MainBranch kolonunu değiştirdim.\n",
    "survey_19['MainBranch'].replace({'I am a student who is learning to code': 'Student',\n",
    "  'I am not primarily a developer, but I write code sometimes as part of my work': 'Not a Developer',\n",
    "  'I am a developer by profession':  'Developer',\n",
    "  'I code primarily as a hobby':   'Code as hobby',\n",
    "  'I used to be a developer by profession, but no longer am': 'Was a Developer'}, inplace=True)\n",
    "\n",
    "\n",
    "#respondent sütununu index olarak ayarladım.\n",
    "survey_19.set_index('Respondent', inplace = True)\n",
    "\n",
    "\n",
    "#Haftalık çalışma saati (WorkWeekHrs) ya da yıllık maaş (ConvertedComp) sütunlarındaki değerleri, \n",
    "#ilgili sütunun ortalamasının %99'undan daha uzakta veri içeren satırları sildim.\n",
    "survey_19.drop(survey_19[(survey_19['WorkWeekHrs'] > survey_19['WorkWeekHrs'].mean()*1.99)\n",
    "                         |(survey_19['WorkWeekHrs'] < survey_19['WorkWeekHrs'].mean()*0.01)].index, inplace = True)\n",
    "\n",
    "survey_19.drop(survey_19[(survey_19['ConvertedComp'] > survey_19['ConvertedComp'].mean()*1.99)|\n",
    "                         (survey_19['ConvertedComp'] < survey_19['ConvertedComp'].mean()*0.01)].index, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "survey_19['CompTotal'].loc[survey_19['CompFreq'] == 'Monthly'] *= 12\n",
    "survey_19['CompTotal'].loc[survey_19['CompFreq']=='Weekly'] *= 50\n",
    "\n",
    "survey_19.YearsCode.replace({'Less than 1 year': 1, 'More than 50 years':50}, inplace=True)\n",
    "survey_19.YearsCodePro.replace({'Less than 1 year': 1, 'More than 50 years':50}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bu soruda kullanmak için seçtiğim öznitelikler\n",
    "usecols=['MainBranch','Hobbyist','WorkWeekHrs','YearsCodePro','YearsCode','CodeRevHrs','EdLevel','OpenSourcer']\n",
    "\n",
    "# Katkıda bulunuyor = 1, Katkıda bulunmuyor = 0 olarak güncellenmesi\n",
    "survey_19.OpenSourcer.replace(to_replace=[\"Less than once per year\",\"Never\"], value = 0,inplace=True)\n",
    "survey_19.OpenSourcer.replace(to_replace=[\"Less than once a month but more than once per year\",\"Once a month or more often\"],\n",
    "                              value = 1,inplace=True)\n",
    "#kolon tipinin objectten int e dönüşmesi için bu işlemi yaptım. \n",
    "survey_19.YearsCode.replace({'Less than 1 year': 1, 'More than 50 years':50}, inplace=True)\n",
    "survey_19.YearsCodePro.replace({'Less than 1 year': 1, 'More than 50 years':50}, inplace=True)\n",
    "\n",
    "#kategorik verinin yerine 1 ve 0 verilmesi\n",
    "survey_19.Hobbyist.replace({'Yes':1, 'No':0}, inplace=True)\n",
    "\n",
    "#1. soru için kullancağım dataset\n",
    "df1 = survey_19[usecols]\n",
    "\n",
    "#OneHotEncoding yapılması gereken kolonlar ve df1 e eklenmesi\n",
    "dummy_list = ['MainBranch','EdLevel']\n",
    "dummy_df = pd.get_dummies(survey_19[dummy_list])\n",
    "df1 = pd.concat([df1,dummy_df], axis=1)\n",
    "df1.drop(dummy_list, inplace=True, axis=1)\n",
    "\n",
    "#boş olan verilerin yerine kolon ortalamalarını koymayı uygun gördüm. tamamen sildiğimizde veri sayısı çok azalıyordu.\n",
    "df1.WorkWeekHrs.fillna(df1.WorkWeekHrs.mean(), inplace=True)\n",
    "df1.YearsCode.fillna(df1.WorkWeekHrs.mean(), inplace=True)\n",
    "df1.YearsCodePro.fillna(df1.WorkWeekHrs.mean(), inplace=True)\n",
    "df1.CodeRevHrs.fillna(df1.WorkWeekHrs.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verisetinin bağımlı ve bağımsız değişkene ayrılması\n",
    "X = df1.loc[:,df1.columns != 'OpenSourcer']\n",
    "y = df1.OpenSourcer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Veri setinin train ve test olarak ayrılması\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of Logistic Regression is 0.6469096891551335\n",
      "Accuracy score of Decision Tree is 0.6075034883230964\n",
      "Accuracy score of KNeighbors Classifier is 0.6103854523717922\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "lr = LogisticRegression()\n",
    "params = {'max_iter': [1000],'penalty': ['none', 'l2'], 'solver':['newton-cg', 'lbfgs','sag', 'saga']}\n",
    "g_search = GridSearchCV(estimator=lr,param_grid=params, cv=10)\n",
    "g_search.fit(X,y)\n",
    "print(\"Accuracy score of Logistic Regression is \"+str(g_search.best_score_))\n",
    "\n",
    "DTclf = DecisionTreeClassifier()\n",
    "params = {'criterion':['gini', 'entropy'], 'splitter':['best','random']}\n",
    "g_search = GridSearchCV(estimator=DTclf,param_grid=params, cv=10)\n",
    "g_search.fit(X,y)\n",
    "print(\"Accuracy score of Decision Tree is \"+str(g_search.best_score_))\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "params = {'n_neighbors' : [3,5,7], 'weights': ['distance','uniform']}\n",
    "g_search = GridSearchCV(estimator=knn,param_grid=params, cv=10)\n",
    "g_search.fit(X,y)\n",
    "print(\"Accuracy score of KNeighbors Classifier is \"+str(g_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Numan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Numan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Numan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Numan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\Numan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Hobbyist', True, 1),\n",
       " ('WorkWeekHrs', False, 15),\n",
       " ('YearsCodePro', False, 14),\n",
       " ('YearsCode', False, 10),\n",
       " ('CodeRevHrs', False, 13),\n",
       " ('MainBranch_Code as hobby', False, 2),\n",
       " ('MainBranch_Developer', False, 3),\n",
       " ('MainBranch_Not a Developer', True, 1),\n",
       " ('MainBranch_Student', True, 1),\n",
       " ('MainBranch_Was a Developer', True, 1),\n",
       " ('EdLevel_Associate degree', False, 12),\n",
       " ('EdLevel_Bachelor’s degree (BA, BS, B.Eng., etc.)', False, 4),\n",
       " ('EdLevel_I never completed any formal education', False, 9),\n",
       " ('EdLevel_Master’s degree (MA, MS, M.Eng., MBA, etc.)', False, 7),\n",
       " ('EdLevel_Other doctoral degree (Ph.D, Ed.D., etc.)', True, 1),\n",
       " ('EdLevel_Primary/elementary school', False, 5),\n",
       " ('EdLevel_Professional degree (JD, MD, etc.)', False, 6),\n",
       " ('EdLevel_Secondary school (e.g. American high school, German Realschule or Gymnasium, etc.)',\n",
       "  False,\n",
       "  8),\n",
       " ('EdLevel_Some college/university study without earning a degree', False, 11)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hangi kolonların model için daha anlamlı olduğunu bulmak için RFE sınıfını kullanıyorum.\n",
    "#En anlamlı 5 kolonu seçeceğiz. Burda model olarak Logistic Regresyon kullandım. Çünkü en yüksek accuracy scoruu bu modelden\n",
    "#elde ettim. Çıktıda True olarak verilen sütunlar en anlamlı 5 kolon olarak söyleyebiliriz.\n",
    "from sklearn.feature_selection import RFE\n",
    "rfe = RFE(lr, n_features_to_select=5)\n",
    "rfe = rfe.fit(X_train, y_train)\n",
    "\n",
    "list(zip(X_train.columns,rfe.support_, rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tahmin edilen: Katkıda bulunmuyor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Numan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "new_data = np.array([1, 70, 10,15,30,0,1,0,0,0,0,1,0,0,0,0,0,0,0])\n",
    "lr.fit(X,y)\n",
    "if(lr.predict(new_data.reshape(1,-1)) == 0):\n",
    "    print(\"Tahmin edilen: \"+ \"Katkıda bulunmuyor.\")\n",
    "else:\n",
    "    print(\"Tahmin edilen: \"+ \"Katkıda bulunuyor.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
